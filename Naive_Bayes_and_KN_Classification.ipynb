{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lab: Naive Bayes, K-NN classifiers, and text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab we will work with a subset of the 20 newsgroup data that was mentioned during the Naive Bayes discussion in class. \n",
    "\n",
    "## Data\n",
    "\n",
    "The 20 newsgroups dataset comprises around 18000 newsgroups posts on 20 topics. The classification problem is to identify the newsgroup a post was summited to, given the text of the post.\n",
    "\n",
    "There are a few versions of this dataset from different sources online. Below, we use the version within scikit-learn which is already split into a train and test/eval set. For a longer introduction to this dataset, see the scikit-learn website: http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html\n",
    "\n",
    "\n",
    "### Let's download the data and take a look at the target names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "data = fetch_20newsgroups()\n",
    "data.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For simplicity here, we will select just a few of these categories, and download the training and testing set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['alt.atheism', 'soc.religion.christian','comp.graphics', 'sci.med', 'sci.space',\n",
    "              'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey']\n",
    "\n",
    "# load training data\n",
    "twenty_train = fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### target_names holds the list of the requested category names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alt.atheism', 'comp.graphics', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.med', 'sci.space', 'soc.religion.christian'] \n",
      "\n",
      "5824\n"
     ]
    }
   ],
   "source": [
    "# print the class names\n",
    "print (twenty_train.target_names, \"\\n\")\n",
    "\n",
    "# The files themselves are loaded in memory in the data attribute. For reference the filenames are also available\n",
    "print(len(twenty_train.data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For speed and space efficiency reasons scikit-learn loads the target attribute as an array of integers that corresponds to the index of the category name in the target_names list. The category integer id of each sample is stored in the target attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 9, 2, 5, 8, 0, 6, 2, 5, 6, 9, 4, 1, 6, 5, 8, 2, 1, 5, 5, 1, 3,\n",
       "       3, 9, 1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_train.target[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 rec.sport.hockey\n",
      "6 rec.sport.hockey\n",
      "2 misc.forsale\n",
      "0 alt.atheism\n",
      "5 rec.sport.baseball\n",
      "6 rec.sport.hockey\n",
      "6 rec.sport.hockey\n",
      "2 misc.forsale\n",
      "0 alt.atheism\n",
      "6 rec.sport.hockey\n",
      "6 rec.sport.hockey\n",
      "8 sci.space\n",
      "9 soc.religion.christian\n",
      "6 rec.sport.hockey\n",
      "0 alt.atheism\n",
      "5 rec.sport.baseball\n",
      "2 misc.forsale\n",
      "9 soc.religion.christian\n",
      "0 alt.atheism\n",
      "0 alt.atheism\n",
      "9 soc.religion.christian\n",
      "5 rec.sport.baseball\n",
      "5 rec.sport.baseball\n",
      "6 rec.sport.hockey\n",
      "9 soc.religion.christian\n",
      "\n",
      " [\"From: huot@cray.com (Tom Huot)\\nSubject: Re: Ulf and all...\\nLines: 29\\nNntp-Posting-Host: pittpa.cray.com\\nOrganization: Cray Research Inc.\\nX-Newsreader: TIN [version 1.1 PL8]\\n\\nRichard Wernick (richard@amc.com) wrote:\\n: You should be ashamed to call yourself an Ulf Samuelson fan. Anybody who plays\\n: the way he does, does not belong in the NHL. There have been cheap shot artists\\n: through the history of the game, but a lot of them have been talanted players.\\n: Bobby Clarke, Kenny Linsemen, Pie McKenzie, Chris Chelios etc.. but nobody has been\\n: out right as dirty a cheapshot coward as Ulf. Violence in hockey has got to be curbed\\n: and players like (Should have been a Women) Samuelson don't belong. When players\\n: like Ulf, who's main purpose is to injure the better players in the league is allowed\\n: to continue, and the league won't stop it, the players should. A Christian Pro 1000\\n: aluminum stick directed at his ugly head should do the trick nicely. If the Bruins get\\n: a chance to meet Pittsburgh in the near future, you can bet Neely will have his day.\\n: The sight of watching Ulf turtle up like the coward he is, is worth almost as much as a\\n: Stanely Cup. This wimp of a player almost ruined the career of one the best right wingers\\n: in the game. If you are to remove Ulf Samuelson from the lineup, the Penguins would not\\n: even notice he's gone. He's an eyesore on the game of hockey.\\n\\n\\n: Rich\\n\\n\\nThank you for your extremely lucid and well thought out observation.\\nNow when you get back on your medication, please let us know how you\\nare feeling. \\nThank you,\\n--\\n_____________________________________________________________________________\\nTom Huot        \\t\\t\\t       \\nhuot@cray.com \\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\n\"]\n"
     ]
    }
   ],
   "source": [
    "# print the class names for the first 25 articles\n",
    "for t in twenty_train.target[:25]:\n",
    "    target_id = twenty_train.target[t]\n",
    "    print(target_id, twenty_train.target_names[target_id])\n",
    "    \n",
    "# print the first article\n",
    "print(\"\\n\", twenty_train.data[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the data to word counts and see how many times the word 'algorithm' appears\n",
    "In order to use this data for machine learning, we need to be able to convert the content of each string into a vector of numbers. One of the simplest methods of encoding data is by word counts: you take each snippet of text, count the occurrences of each word within it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10285"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import and use CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(twenty_train.data)\n",
    "\n",
    "count_vect.vocabulary_.get(u'algorithm')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Naive Bayes\n",
    "Multinomial naive Bayes is often used is in text classification, where the features are related to word counts or frequencies within the documents to be classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9223426212590299\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       0.91      0.87      0.89       319\n",
      "         comp.graphics       0.90      0.91      0.90       389\n",
      "          misc.forsale       0.95      0.85      0.90       390\n",
      "             rec.autos       0.87      0.95      0.91       396\n",
      "       rec.motorcycles       0.97      0.95      0.96       398\n",
      "    rec.sport.baseball       0.97      0.93      0.95       397\n",
      "      rec.sport.hockey       0.95      0.97      0.96       399\n",
      "               sci.med       0.95      0.86      0.90       396\n",
      "             sci.space       0.92      0.94      0.93       394\n",
      "soc.religion.christian       0.87      0.97      0.92       398\n",
      "\n",
      "              accuracy                           0.92      3876\n",
      "             macro avg       0.92      0.92      0.92      3876\n",
      "          weighted avg       0.92      0.92      0.92      3876\n",
      "\n",
      "[[276   1   1   2   1   1   2   2   3  30]\n",
      " [  5 354   2   5   0   2   2   5  11   3]\n",
      " [  0  16 333  24   2   1   3   4   6   1]\n",
      " [  0   2   6 378   3   1   2   0   4   0]\n",
      " [  0   0   3  12 380   0   0   0   1   2]\n",
      " [  3   1   2   6   0 370  11   0   3   1]\n",
      " [  0   0   0   1   0   5 387   1   1   4]\n",
      " [ 10   9   4   4   7   3   1 342   3  13]\n",
      " [  6   9   1   1   0   0   0   4 369   4]\n",
      " [  4   2   0   0   0   0   1   3   2 386]]\n"
     ]
    }
   ],
   "source": [
    "# Import Multinomial NB (this a good Naive Bayes classifier for text) and other libraries to help with analysis\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "# fit classifier using word counts\n",
    "clf_1 = MultinomialNB().fit(X_train_counts, twenty_train.target)\n",
    "\n",
    "# load the test data set and convert to word counts\n",
    "twenty_test = fetch_20newsgroups(subset='test', categories=categories, shuffle=True, random_state=42)\n",
    "\n",
    "# note that I am using .transform instead of .fit_transform. this keeps the columns the same as the training set\n",
    "X_test_counts = count_vect.transform(twenty_test.data)\n",
    "\n",
    "# make predictions on test data\n",
    "predicted = clf_1.predict(X_test_counts)\n",
    "\n",
    "# print accuracy\n",
    "print (np.mean(predicted == twenty_test.target)) \n",
    "\n",
    "# print precision and recall statistics\n",
    "print(metrics.classification_report(twenty_test.target, predicted,\n",
    "    target_names=twenty_test.target_names))\n",
    "\n",
    "# print confusion matrix\n",
    "print(metrics.confusion_matrix(twenty_test.target, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the data to a TF-IDF representation and run Naive Bayes\n",
    "There are often issues with word count approach where the raw word counts lead to features which put too much weight on words that appear very frequently, and this can be sub-optimal in some classification algorithms. One approach to fix this is known as term frequency-inverse document frequency (TFâ€“IDF) which weights the word counts by a measure of how often they appear in the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.868937048503612\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       0.97      0.55      0.70       319\n",
      "         comp.graphics       0.93      0.83      0.88       389\n",
      "          misc.forsale       0.96      0.83      0.89       390\n",
      "             rec.autos       0.88      0.94      0.91       396\n",
      "       rec.motorcycles       0.94      0.94      0.94       398\n",
      "    rec.sport.baseball       0.94      0.90      0.92       397\n",
      "      rec.sport.hockey       0.92      0.97      0.94       399\n",
      "               sci.med       0.94      0.77      0.85       396\n",
      "             sci.space       0.92      0.91      0.91       394\n",
      "soc.religion.christian       0.58      0.98      0.73       398\n",
      "\n",
      "              accuracy                           0.87      3876\n",
      "             macro avg       0.90      0.86      0.87      3876\n",
      "          weighted avg       0.90      0.87      0.87      3876\n",
      "\n",
      "[[175   1   0   0   2   1   1   6   3 130]\n",
      " [  1 322   2   9   3   7   2   1  10  32]\n",
      " [  0  10 322  20   5   4   5   6   4  14]\n",
      " [  0   3   5 373   3   2   3   1   3   3]\n",
      " [  0   0   2  12 375   0   0   0   0   9]\n",
      " [  0   0   1   4   0 358  21   0   2  11]\n",
      " [  0   0   0   1   0   4 388   0   1   5]\n",
      " [  2   6   3   1   7   5   3 305   7  57]\n",
      " [  0   4   0   2   1   0   1   4 360  22]\n",
      " [  2   1   0   0   1   0   0   1   3 390]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "clf_2 = MultinomialNB().fit(X_train_tfidf, twenty_train.target)\n",
    "\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_counts)\n",
    "\n",
    "# make predictions on test data\n",
    "predicted = clf_2.predict(X_test_tfidf)\n",
    "\n",
    "# print accuracy\n",
    "print (np.mean(predicted == twenty_test.target)) \n",
    "\n",
    "# print precision and recall statistics\n",
    "print(metrics.classification_report(twenty_test.target, predicted,\n",
    "    target_names=twenty_test.target_names))\n",
    "\n",
    "# print confusion matrix\n",
    "print(metrics.confusion_matrix(twenty_test.target, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a pipeline for Naive Bayes for TF-IDF and rerun experiments\n",
    "It works by allowing several transformers to be chained together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.868937048503612\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       0.97      0.55      0.70       319\n",
      "         comp.graphics       0.93      0.83      0.88       389\n",
      "          misc.forsale       0.96      0.83      0.89       390\n",
      "             rec.autos       0.88      0.94      0.91       396\n",
      "       rec.motorcycles       0.94      0.94      0.94       398\n",
      "    rec.sport.baseball       0.94      0.90      0.92       397\n",
      "      rec.sport.hockey       0.92      0.97      0.94       399\n",
      "               sci.med       0.94      0.77      0.85       396\n",
      "             sci.space       0.92      0.91      0.91       394\n",
      "soc.religion.christian       0.58      0.98      0.73       398\n",
      "\n",
      "              accuracy                           0.87      3876\n",
      "             macro avg       0.90      0.86      0.87      3876\n",
      "          weighted avg       0.90      0.87      0.87      3876\n",
      "\n",
      "[[175   1   0   0   2   1   1   6   3 130]\n",
      " [  1 322   2   9   3   7   2   1  10  32]\n",
      " [  0  10 322  20   5   4   5   6   4  14]\n",
      " [  0   3   5 373   3   2   3   1   3   3]\n",
      " [  0   0   2  12 375   0   0   0   0   9]\n",
      " [  0   0   1   4   0 358  21   0   2  11]\n",
      " [  0   0   0   1   0   4 388   0   1   5]\n",
      " [  2   6   3   1   7   5   3 305   7  57]\n",
      " [  0   4   0   2   1   0   1   4 360  22]\n",
      " [  2   1   0   0   1   0   0   1   3 390]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "clf_3 = Pipeline([('vect', CountVectorizer()),\n",
    "                  ('tfidf', TfidfTransformer()),\n",
    "                  ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "clf_3.fit(twenty_train.data, twenty_train.target)\n",
    "\n",
    "# make predictions on test data\n",
    "predicted = clf_3.predict(twenty_test.data)\n",
    "\n",
    "# print accuracy\n",
    "print (np.mean(predicted == twenty_test.target)) \n",
    "\n",
    "# print precision and recall statistics\n",
    "print(metrics.classification_report(twenty_test.target, predicted,\n",
    "    target_names=twenty_test.target_names))\n",
    "\n",
    "# print confusion matrix\n",
    "print(metrics.confusion_matrix(twenty_test.target, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  We can now determine the category for any string, using the predict() method of this pipeline. Here's a quick utility function that will return the prediction for a single string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_category(s, train=twenty_train, model=clf_3):\n",
    "    pred = model.predict([s])\n",
    "    return train.target_names[pred[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sci.space'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_category('sending a payload to the ISS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'alt.atheism'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_category('discussing islam vs atheism')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'comp.graphics'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_category('determining the screen resolution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and test a nearest-neighbor classfier using word counts and 5 neighbors (default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4538183694530444\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       0.46      0.53      0.49       319\n",
      "         comp.graphics       0.25      0.50      0.34       389\n",
      "          misc.forsale       0.72      0.48      0.58       390\n",
      "             rec.autos       0.35      0.40      0.37       396\n",
      "       rec.motorcycles       0.74      0.49      0.59       398\n",
      "    rec.sport.baseball       0.46      0.36      0.40       397\n",
      "      rec.sport.hockey       0.50      0.52      0.51       399\n",
      "               sci.med       0.53      0.26      0.35       396\n",
      "             sci.space       0.84      0.36      0.50       394\n",
      "soc.religion.christian       0.38      0.66      0.48       398\n",
      "\n",
      "              accuracy                           0.45      3876\n",
      "             macro avg       0.53      0.46      0.46      3876\n",
      "          weighted avg       0.53      0.45      0.46      3876\n",
      "\n",
      "[[168  23   6  16   4  13   9   9   2  69]\n",
      " [ 19 195  15  36   8  15  20   7   8  66]\n",
      " [  6 125 187  22   3   6  12   4   1  24]\n",
      " [ 19  75   9 158  14  28  29  15   3  46]\n",
      " [ 11  47   9  48 195  15  22  11   0  40]\n",
      " [ 32  70   9  34   8 141  46  11   4  42]\n",
      " [ 12  52   5  32   7  49 207   2   1  32]\n",
      " [ 29  86  11  50  12  13  22 103   4  66]\n",
      " [ 25  64   6  30  10  15  31  21 141  51]\n",
      " [ 42  32   1  21   2   9  12  12   3 264]]\n"
     ]
    }
   ],
   "source": [
    "# k-means\n",
    "from sklearn import neighbors\n",
    "\n",
    "clf_5=neighbors.KNeighborsClassifier(n_neighbors = 5) # don't need argument here but do later\n",
    "\n",
    "# we create an instance of Neighbours Classifier and fit the data.\n",
    "clf_5.fit(X_train_counts, twenty_train.target)\n",
    "\n",
    "predicted = clf_5.predict(X_test_counts)\n",
    "\n",
    "print (np.mean(predicted == twenty_test.target)) \n",
    "\n",
    "print(metrics.classification_report(twenty_test.target, predicted,\n",
    "    target_names=twenty_test.target_names))\n",
    "\n",
    "print(metrics.confusion_matrix(twenty_test.target, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color=\"red\" size=5> Create and test a nearest-neighbor classfier using TF-IDF vectors and 5 neighbors (default)</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7647058823529411\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       0.52      0.85      0.64       319\n",
      "         comp.graphics       0.74      0.73      0.73       389\n",
      "          misc.forsale       0.76      0.66      0.71       390\n",
      "             rec.autos       0.80      0.79      0.79       396\n",
      "       rec.motorcycles       0.84      0.83      0.83       398\n",
      "    rec.sport.baseball       0.82      0.78      0.80       397\n",
      "      rec.sport.hockey       0.86      0.88      0.87       399\n",
      "               sci.med       0.89      0.54      0.67       396\n",
      "             sci.space       0.86      0.77      0.81       394\n",
      "soc.religion.christian       0.71      0.84      0.77       398\n",
      "\n",
      "              accuracy                           0.76      3876\n",
      "             macro avg       0.78      0.77      0.76      3876\n",
      "          weighted avg       0.78      0.76      0.77      3876\n",
      "\n",
      "[[270   2   5   1   0   1   0   7   5  28]\n",
      " [ 35 285  13  14   9   8   5   3   9   8]\n",
      " [ 11  31 256  17  21  17  10   6  11  10]\n",
      " [ 16  17  15 313  11   6   7   2   2   7]\n",
      " [ 17   3   9  18 329   2   4   2   2  12]\n",
      " [ 27   6   8   8   6 311  16   0   7   8]\n",
      " [ 12   6   5   1   2  11 350   1   1  10]\n",
      " [ 59  14  18  11  12  16   7 212   6  41]\n",
      " [ 33  20   6   8   3   4   3   3 305   9]\n",
      " [ 44   3   1   1   0   2   4   3   7 333]]\n"
     ]
    }
   ],
   "source": [
    "# insert code here\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn import neighbors\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "clf_x=neighbors.KNeighborsClassifier(n_neighbors = 5)\n",
    "clf_x.fit(X_train_tfidf, twenty_train.target)\n",
    "predicted = clf_x.predict(X_test_tfidf)\n",
    "\n",
    "\n",
    "# clf_2 = MultinomialNB().fit(X_train_tfidf, twenty_train.target)\n",
    "\n",
    "# X_test_tfidf = tfidf_transformer.transform(X_test_counts)\n",
    "\n",
    "# # make predictions on test data\n",
    "# predicted = clf_2.predict(X_test_tfidf)\n",
    "\n",
    "# # print accuracy\n",
    "# print (np.mean(predicted == twenty_test.target)) \n",
    "\n",
    "# # print precision and recall statistics\n",
    "# print(metrics.classification_report(twenty_test.target, predicted,\n",
    "#     target_names=twenty_test.target_names))\n",
    "\n",
    "# # print confusion matrix\n",
    "# print(metrics.confusion_matrix(twenty_test.target, predicted))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# predicted = clf_5.predict(X_test_counts)\n",
    "\n",
    "print (np.mean(predicted == twenty_test.target)) \n",
    "\n",
    "print(metrics.classification_report(twenty_test.target, predicted,\n",
    "    target_names=twenty_test.target_names))\n",
    "\n",
    "print(metrics.confusion_matrix(twenty_test.target, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color=\"red\" size=5> Using TF-IDF vectors, write code that uses grid search to select the number of neighbors</font>**</br>\n",
    "<font size=3>Use grid search to assess n_neighbor values of 1, 3, 5 and weights parameters of 'uniform' and 'distance'</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 1, 'weights': 'uniform'}\n",
      "KNeighborsClassifier(n_neighbors=1)\n",
      "0.7763157894736842\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       0.64      0.84      0.73       319\n",
      "         comp.graphics       0.71      0.71      0.71       389\n",
      "          misc.forsale       0.76      0.64      0.70       390\n",
      "             rec.autos       0.82      0.75      0.78       396\n",
      "       rec.motorcycles       0.83      0.86      0.84       398\n",
      "    rec.sport.baseball       0.79      0.79      0.79       397\n",
      "      rec.sport.hockey       0.83      0.86      0.85       399\n",
      "               sci.med       0.84      0.67      0.75       396\n",
      "             sci.space       0.82      0.85      0.83       394\n",
      "soc.religion.christian       0.74      0.80      0.77       398\n",
      "\n",
      "              accuracy                           0.78      3876\n",
      "             macro avg       0.78      0.78      0.77      3876\n",
      "          weighted avg       0.78      0.78      0.78      3876\n",
      "\n",
      "[[267   3   5   1   3   3   0   8   7  22]\n",
      " [ 17 276  18  15   8   9  10   8  16  12]\n",
      " [  4  31 250  12  17  26  16   5  16  13]\n",
      " [  8  18  16 298  17   7   8  10  11   3]\n",
      " [ 12   8   2  14 341   4   3   7   3   4]\n",
      " [ 13   8   7  10   3 314  19   2   5  16]\n",
      " [  7   8   9   2   1  14 345   3   3   7]\n",
      " [ 28  18  14   4  14  14   5 266   4  29]\n",
      " [ 11  15   5   7   4   3   3   5 333   8]\n",
      " [ 49   4   1   2   4   1   5   3  10 319]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import neighbors\n",
    "# finish the function below\n",
    "gs_params = {\"n_neighbors\": [1,3,5],\n",
    "              \"weights\": ['uniform', 'distance']  \n",
    "             }\n",
    "est = neighbors.KNeighborsClassifier()\n",
    "gs_clf = GridSearchCV(estimator=est, param_grid=gs_params)\n",
    "gs_results = gs_clf.fit(X_train_tfidf, twenty_train.target)\n",
    "\n",
    "print(gs_results.best_params_)\n",
    "\n",
    "print(gs_results.best_estimator_)\n",
    "\n",
    "best_clf = gs_results.best_estimator_\n",
    "gs_predicted = gs_clf.predict(X_test_tfidf)\n",
    "\n",
    "print (np.mean(gs_predicted == twenty_test.target)) \n",
    "\n",
    "print(metrics.classification_report(twenty_test.target, gs_predicted,\n",
    "    target_names=twenty_test.target_names))\n",
    "\n",
    "print(metrics.confusion_matrix(twenty_test.target, gs_predicted))\n",
    "\n",
    "# assess the best classifier the same way as done above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color=\"red\" size=5> Use gridsearchcv to compare the performance of count vectors to TFIDF vectors on just the comp.* subset of newsgroups</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 comp.sys.ibm.pc.hardware\n",
      "1 comp.os.ms-windows.misc\n",
      "3 comp.sys.mac.hardware\n",
      "3 comp.sys.mac.hardware\n",
      "1 comp.os.ms-windows.misc\n",
      "4 comp.windows.x\n",
      "3 comp.sys.mac.hardware\n",
      "1 comp.os.ms-windows.misc\n",
      "1 comp.os.ms-windows.misc\n",
      "4 comp.windows.x\n",
      "4 comp.windows.x\n",
      "1 comp.os.ms-windows.misc\n",
      "1 comp.os.ms-windows.misc\n",
      "2 comp.sys.ibm.pc.hardware\n",
      "2 comp.sys.ibm.pc.hardware\n",
      "1 comp.os.ms-windows.misc\n",
      "2 comp.sys.ibm.pc.hardware\n",
      "2 comp.sys.ibm.pc.hardware\n",
      "1 comp.os.ms-windows.misc\n",
      "2 comp.sys.ibm.pc.hardware\n",
      "3 comp.sys.mac.hardware\n",
      "1 comp.os.ms-windows.misc\n",
      "2 comp.sys.ibm.pc.hardware\n",
      "2 comp.sys.ibm.pc.hardware\n",
      "4 comp.windows.x\n",
      "\n",
      " [\"From: lemons@cadsys.enet.dec.com\\nSubject: Xremote into X11R6?\\nReply-To: lemons@cadsys.enet.dec.com ()\\nOrganization: Digital Equipment Corporation\\nLines: 12\\nX-Newsreader: mxrn 6.18\\n\\n\\nHi!\\n\\nI remember reading (or hallucinating) that NCD's PC-Xremote functionality had \\nbeen given, by NCD, to MIT for inclusion in X11R6.  Is this true?  If so,\\n(set mode/cheap) can I just wait for X11R6 to get compressed serial line\\nX server support?\\n\\nThanks!\\n\\nTerry Lemons\\nDigital Equipment Corporation\\n\"]\n"
     ]
    }
   ],
   "source": [
    "# insert code to read in appropriate newsgroup data here\n",
    "cats = ['comp.graphics',\n",
    " 'comp.os.ms-windows.misc',\n",
    " 'comp.sys.ibm.pc.hardware',\n",
    " 'comp.sys.mac.hardware',\n",
    " 'comp.windows.x']\n",
    "\n",
    "our_train = fetch_20newsgroups(subset='train', categories=cats, shuffle=True, random_state=42)\n",
    "our_train.target[:25]\n",
    "for p in our_train.target[:25]:\n",
    "    target_id = our_train.target[p]\n",
    "    print(target_id, our_train.target_names[target_id])\n",
    "\n",
    "# print the first article\n",
    "print(\"\\n\", our_train.data[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15462"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "ct_vec = CountVectorizer()\n",
    "X_Train_counts = ct_vec.fit_transform(our_train.data)\n",
    "\n",
    "ct_vec.vocabulary_.get(u'algorithm')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ['From: donn@carson.u.washington.edu (Donn Cave)\\nSubject: Re: Anyone know use \"rayshade\" out there?\\nOrganization: University of Washington\\nLines: 13\\nNNTP-Posting-Host: carson.u.washington.edu\\nKeywords: rayshade, uw.\\n\\nfineman@stein2.u.washington.edu (Twixt your toes) writes:\\n\\n| I\\'m using \"rayshade\" on the u.w. computers here, and i\\'d like input\\n| from other users, and perhaps swap some ideas.  I could post\\n| uuencoded .gifs here, or .ray code, if anyone\\'s interested.  I\\'m having\\n| trouble coming up with colors that are metallic (i.e. brass, steel)\\n| from the RGB values.\\n\\nSorry, I\\'m not a rayshade user - but hey, it looks like this group could\\nuse some traffic.  My guess is that \"metallic\" isn\\'t a color, in the RGB\\nsense.  Rather, it\\'s a matter of how the surface reflects light.  I\\'m not\\nsure what property metallic materials have, that makes them recognizable\\nas such, but I\\'m pretty sure any color material can look metallic.\\n']\n"
     ]
    }
   ],
   "source": [
    "our_test = fetch_20newsgroups(subset='test', categories=categories, shuffle=True, random_state=42)\n",
    "\n",
    "# note that I am using .transform instead of .fit_transform. this keeps the columns the same as the training set\n",
    "X_Test_counts = ct_vec.transform(our_test.data)\n",
    "\n",
    "print(\"\\n\", our_test.data[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09236326109391124\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       0.08      0.44      0.14       319\n",
      "         comp.graphics       0.10      0.14      0.12       389\n",
      "          misc.forsale       0.09      0.09      0.09       390\n",
      "             rec.autos       0.11      0.28      0.16       396\n",
      "       rec.motorcycles       0.10      0.05      0.06       398\n",
      "    rec.sport.baseball       0.00      0.00      0.00       397\n",
      "      rec.sport.hockey       0.00      0.00      0.00       399\n",
      "               sci.med       0.00      0.00      0.00       396\n",
      "             sci.space       0.00      0.00      0.00       394\n",
      "soc.religion.christian       0.00      0.00      0.00       398\n",
      "\n",
      "              accuracy                           0.09      3876\n",
      "             macro avg       0.05      0.10      0.06      3876\n",
      "          weighted avg       0.05      0.09      0.05      3876\n",
      "\n",
      "[[141  56  32  72  18   0   0   0   0   0]\n",
      " [242  53  21  49  24   0   0   0   0   0]\n",
      " [225  61  35  59  10   0   0   0   0   0]\n",
      " [169  54  48 111  14   0   0   0   0   0]\n",
      " [151  57  36 136  18   0   0   0   0   0]\n",
      " [163  53  50 114  17   0   0   0   0   0]\n",
      " [128  47  57 148  19   0   0   0   0   0]\n",
      " [182  57  35 103  19   0   0   0   0   0]\n",
      " [167  35  52 123  17   0   0   0   0   0]\n",
      " [187  46  43  91  31   0   0   0   0   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbook/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/macbook/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/macbook/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn import neighbors\n",
    "\n",
    "clf_8=neighbors.KNeighborsClassifier(n_neighbors = 5) # don't need argument here but do later\n",
    "\n",
    "# we create an instance of Neighbours Classifier and fit the data.\n",
    "clf_8.fit(X_Train_counts, our_train.target)\n",
    "\n",
    "predicted = clf_8.predict(X_Test_counts)\n",
    "\n",
    "print (np.mean(predicted == our_test.target)) \n",
    "\n",
    "print(metrics.classification_report(our_test.target, predicted,\n",
    "    target_names=twenty_test.target_names))\n",
    "\n",
    "print(metrics.confusion_matrix(our_test.target, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11145510835913312\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       0.05      0.14      0.08       319\n",
      "         comp.graphics       0.08      0.08      0.08       389\n",
      "          misc.forsale       0.26      0.32      0.29       390\n",
      "             rec.autos       0.15      0.15      0.15       396\n",
      "       rec.motorcycles       0.10      0.43      0.16       398\n",
      "    rec.sport.baseball       0.00      0.00      0.00       397\n",
      "      rec.sport.hockey       0.00      0.00      0.00       399\n",
      "               sci.med       0.00      0.00      0.00       396\n",
      "             sci.space       0.00      0.00      0.00       394\n",
      "soc.religion.christian       0.00      0.00      0.00       398\n",
      "\n",
      "              accuracy                           0.11      3876\n",
      "             macro avg       0.06      0.11      0.08      3876\n",
      "          weighted avg       0.06      0.11      0.08      3876\n",
      "\n",
      "[[ 46  16  22  25 210   0   0   0   0   0]\n",
      " [254  31  19  24  61   0   0   0   0   0]\n",
      " [ 47  69 123  95  56   0   0   0   0   0]\n",
      " [ 72  36  56  61 171   0   0   0   0   0]\n",
      " [ 77  41  54  55 171   0   0   0   0   0]\n",
      " [ 87  44  42  43 181   0   0   0   0   0]\n",
      " [ 92  46  65  41 155   0   0   0   0   0]\n",
      " [ 55  35  40  39 227   0   0   0   0   0]\n",
      " [ 89  42  27  21 215   0   0   0   0   0]\n",
      " [ 33  19  17  12 317   0   0   0   0   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbook/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/macbook/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/macbook/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn import neighbors\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "\n",
    "X_Train_tfidf = tfidf_transformer.fit_transform(X_Train_counts)\n",
    "X_Test_tfidf = tfidf_transformer.fit_transform(X_Test_counts)\n",
    "\n",
    "clf_x=neighbors.KNeighborsClassifier(n_neighbors = 5)\n",
    "clf_x.fit(X_Train_tfidf, our_train.target)\n",
    "predicted = clf_x.predict(X_Test_tfidf)\n",
    "\n",
    "print (np.mean(predicted == our_test.target)) \n",
    "\n",
    "print(metrics.classification_report(our_test.target, predicted,\n",
    "    target_names=our_test.target_names))\n",
    "\n",
    "print(metrics.confusion_matrix(our_test.target, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 1, 'weights': 'uniform'}\n",
      "KNeighborsClassifier(n_neighbors=1)\n",
      "0.09313725490196079\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       0.08      0.33      0.13       319\n",
      "         comp.graphics       0.09      0.12      0.10       389\n",
      "          misc.forsale       0.10      0.13      0.11       390\n",
      "             rec.autos       0.11      0.30      0.16       396\n",
      "       rec.motorcycles       0.10      0.10      0.10       398\n",
      "    rec.sport.baseball       0.00      0.00      0.00       397\n",
      "      rec.sport.hockey       0.00      0.00      0.00       399\n",
      "               sci.med       0.00      0.00      0.00       396\n",
      "             sci.space       0.00      0.00      0.00       394\n",
      "soc.religion.christian       0.00      0.00      0.00       398\n",
      "\n",
      "              accuracy                           0.09      3876\n",
      "             macro avg       0.05      0.10      0.06      3876\n",
      "          weighted avg       0.05      0.09      0.06      3876\n",
      "\n",
      "[[106  49  40  93  31   0   0   0   0   0]\n",
      " [216  48  29  59  37   0   0   0   0   0]\n",
      " [161  72  49  84  24   0   0   0   0   0]\n",
      " [125  52  61 118  40   0   0   0   0   0]\n",
      " [115  55  40 148  40   0   0   0   0   0]\n",
      " [127  55  50 128  37   0   0   0   0   0]\n",
      " [101  45  69 133  51   0   0   0   0   0]\n",
      " [148  59  34 103  52   0   0   0   0   0]\n",
      " [120  58  60 102  54   0   0   0   0   0]\n",
      " [140  45  64  98  51   0   0   0   0   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbook/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/macbook/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/macbook/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# insert code to use gridsearchcv to assess count vectors\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import neighbors\n",
    "# finish the function below\n",
    "gs_params = {\"n_neighbors\": [1,3,5],\n",
    "              \"weights\": ['uniform', 'distance']  \n",
    "             }\n",
    "est = neighbors.KNeighborsClassifier()\n",
    "gs_clf = GridSearchCV(estimator=est, param_grid=gs_params)\n",
    "gs_results = gs_clf.fit(X_Train_counts, our_train.target)\n",
    "\n",
    "print(gs_results.best_params_)\n",
    "\n",
    "print(gs_results.best_estimator_)\n",
    "\n",
    "best_clf = gs_results.best_estimator_\n",
    "gs_predicted = gs_clf.predict(X_Test_counts)\n",
    "\n",
    "print (np.mean(gs_predicted == our_test.target)) \n",
    "\n",
    "print(metrics.classification_report(our_test.target, gs_predicted,\n",
    "    target_names=our_test.target_names))\n",
    "\n",
    "print(metrics.confusion_matrix(our_test.target, gs_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 1, 'weights': 'uniform'}\n",
      "KNeighborsClassifier(n_neighbors=1)\n",
      "0.10036119711042311\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       0.06      0.14      0.08       319\n",
      "         comp.graphics       0.07      0.09      0.08       389\n",
      "          misc.forsale       0.18      0.25      0.21       390\n",
      "             rec.autos       0.12      0.16      0.14       396\n",
      "       rec.motorcycles       0.10      0.37      0.15       398\n",
      "    rec.sport.baseball       0.00      0.00      0.00       397\n",
      "      rec.sport.hockey       0.00      0.00      0.00       399\n",
      "               sci.med       0.00      0.00      0.00       396\n",
      "             sci.space       0.00      0.00      0.00       394\n",
      "soc.religion.christian       0.00      0.00      0.00       398\n",
      "\n",
      "              accuracy                           0.10      3876\n",
      "             macro avg       0.05      0.10      0.07      3876\n",
      "          weighted avg       0.05      0.10      0.07      3876\n",
      "\n",
      "[[ 45  27  22  26 199   0   0   0   0   0]\n",
      " [245  35  28  20  61   0   0   0   0   0]\n",
      " [ 53  76  97 100  64   0   0   0   0   0]\n",
      " [ 70  52  63  64 147   0   0   0   0   0]\n",
      " [ 56  42  68  84 148   0   0   0   0   0]\n",
      " [ 67  48  74  62 146   0   0   0   0   0]\n",
      " [ 97  51  75  59 117   0   0   0   0   0]\n",
      " [ 50  54  42  60 190   0   0   0   0   0]\n",
      " [ 79  57  33  47 178   0   0   0   0   0]\n",
      " [ 32  25  30  13 298   0   0   0   0   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbook/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/macbook/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/macbook/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# insert code to use gridsearchcv to assess tfidf vectors\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import neighbors\n",
    "# finish the function below\n",
    "gs_params = {\"n_neighbors\": [1,3,5],\n",
    "              \"weights\": ['uniform', 'distance']  \n",
    "             }\n",
    "est = neighbors.KNeighborsClassifier()\n",
    "gs_clf = GridSearchCV(estimator=est, param_grid=gs_params)\n",
    "gs_results = gs_clf.fit(X_Train_tfidf, our_train.target)\n",
    "\n",
    "print(gs_results.best_params_)\n",
    "\n",
    "print(gs_results.best_estimator_)\n",
    "\n",
    "best_clf = gs_results.best_estimator_\n",
    "gs_predicted = gs_clf.predict(X_Test_tfidf)\n",
    "\n",
    "print (np.mean(gs_predicted == our_test.target)) \n",
    "\n",
    "print(metrics.classification_report(our_test.target, gs_predicted,\n",
    "    target_names=our_test.target_names))\n",
    "\n",
    "print(metrics.confusion_matrix(our_test.target, gs_predicted))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "88de8a03d390c9821a705f8812eeaeda47efe29e530260f109fd5a47346b85c0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
